{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f871d1",
   "metadata": {
    "id": "nUVs0Nmxd0oR",
    "papermill": {
     "duration": 0.008694,
     "end_time": "2024-03-11T21:40:14.457529",
     "exception": false,
     "start_time": "2024-03-11T21:40:14.448835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: black; font-size:180%; text-align:left;padding:3.0px; background: #ffebcc; border-bottom: 8px solid black\" > TABLE OF CONTENTS<br><div>  \n",
    "* [IMPORTS AND INSTALLATIONS](#1)\n",
    "* [INTRODUCTION](#2)\n",
    "    * [UTILITIES](#2.1)\n",
    "    * [DATASET DETAILS](#2.2)    \n",
    "    * [CONFIGURATION](#2.3)\n",
    "    * [VERSION DETAILS](#2.4)\n",
    "* [PREPROCESSING](#3)\n",
    "* [MODEL INFERENCING](#4) \n",
    "    * [MY LGBM-XGB MODELS](#4.1)\n",
    "    * [LAMA DENSELIGHT MODEL](#4.2)\n",
    "* [PLANNED NEXT STEPS](#5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c8a4c",
   "metadata": {
    "id": "FNfLSqY-d79o",
    "papermill": {
     "duration": 0.008047,
     "end_time": "2024-03-11T21:40:14.474324",
     "exception": false,
     "start_time": "2024-03-11T21:40:14.466277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:120%; text-align:left;padding:3.0px; background: #b32d00; border-bottom: 8px solid black\" > PACKAGE IMPORTS AND INSTALLATIONS<br> <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121efcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:40:14.492442Z",
     "iopub.status.busy": "2024-03-11T21:40:14.492064Z",
     "iopub.status.idle": "2024-03-11T21:41:25.931298Z",
     "shell.execute_reply": "2024-03-11T21:41:25.930390Z"
    },
    "id": "F_swKOeVdxjA",
    "outputId": "6cb6f272-5e37-4aaa-f72d-02d7f7ac13b9",
    "papermill": {
     "duration": 71.459574,
     "end_time": "2024-03-11T21:41:25.942124",
     "exception": false,
     "start_time": "2024-03-11T21:40:14.482550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\n",
      "CPU times: user 929 ms, sys: 204 ms, total: 1.13 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import clear_output;\n",
    "from gc import collect;\n",
    "!pip install -q \"/kaggle/input/pythonlibrarieswheelfiles/scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\";\n",
    "!pip install -q \"/kaggle/input/pythonlibrarieswheelfiles/lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl\";\n",
    "\n",
    "print();\n",
    "collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e5122e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:25.959688Z",
     "iopub.status.busy": "2024-03-11T21:41:25.959369Z",
     "iopub.status.idle": "2024-03-11T21:41:27.002343Z",
     "shell.execute_reply": "2024-03-11T21:41:27.001329Z"
    },
    "id": "jEzCkJZmdjzQ",
    "outputId": "e15adce7-9e23-4b86-fb89-9aa6ccf50cc1",
    "papermill": {
     "duration": 1.05442,
     "end_time": "2024-03-11T21:41:27.004736",
     "exception": false,
     "start_time": "2024-03-11T21:41:25.950316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 563 ms, sys: 88.2 ms, total: 651 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gc import collect;\n",
    "from warnings import filterwarnings;\n",
    "filterwarnings('ignore');\n",
    "from IPython.display import display_html, clear_output;\n",
    "import ctypes;\n",
    "libc = ctypes.CDLL(\"libc.so.6\");\n",
    "\n",
    "from pprint import pprint;\n",
    "from functools import partial;\n",
    "\n",
    "from copy import deepcopy;\n",
    "import pandas as pd, numpy as np, polars as pl, os, joblib;\n",
    "import polars.selectors as cs;\n",
    "\n",
    "from os import path, walk, getpid;\n",
    "from psutil import Process;\n",
    "import re;\n",
    "from collections import Counter;\n",
    "from itertools import product;\n",
    "from glob import glob;\n",
    "\n",
    "from colorama import Fore, Style, init;\n",
    "from warnings import filterwarnings;\n",
    "filterwarnings('ignore');\n",
    "from tqdm.notebook import tqdm;\n",
    "\n",
    "print();\n",
    "collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfac99c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:27.022814Z",
     "iopub.status.busy": "2024-03-11T21:41:27.022418Z",
     "iopub.status.idle": "2024-03-11T21:41:31.818932Z",
     "shell.execute_reply": "2024-03-11T21:41:31.818043Z"
    },
    "id": "1yoUc7f4dp0g",
    "outputId": "fa206e98-aa2e-466c-e7c9-446657f30270",
    "papermill": {
     "duration": 4.80819,
     "end_time": "2024-03-11T21:41:31.821316",
     "exception": false,
     "start_time": "2024-03-11T21:41:27.013126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM = 4.3.0| XGBoost = 2.0.3\n",
      "\n",
      "\n",
      "CPU times: user 3.22 s, sys: 320 ms, total: 3.54 s\n",
      "Wall time: 4.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pipeline specifics:-\n",
    "from sklearn.model_selection import (StratifiedGroupKFold as SGKF, cross_val_score, cross_val_predict);\n",
    "from sklearn.pipeline import Pipeline;\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin;\n",
    "\n",
    "# ML Model training:-\n",
    "from sklearn.metrics import roc_auc_score, make_scorer;\n",
    "from xgboost import DMatrix, XGBClassifier as XGBC;\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMClassifier as LGBMC;\n",
    "from catboost import CatBoostClassifier as CBC, Pool;\n",
    "from sklearn.ensemble import VotingClassifier as VC;\n",
    "clear_output();\n",
    "\n",
    "import lightgbm as lgb, xgboost as xgb;\n",
    "print(f\"\\nLightGBM = {lgb.__version__}| XGBoost = {xgb.__version__}\\n\\n\");\n",
    "collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2d8bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:31.839480Z",
     "iopub.status.busy": "2024-03-11T21:41:31.839183Z",
     "iopub.status.idle": "2024-03-11T21:41:31.848015Z",
     "shell.execute_reply": "2024-03-11T21:41:31.847117Z"
    },
    "id": "BqljJU3Tecz0",
    "outputId": "ee02e66e-aefb-4e4a-9328-c81466226988",
    "papermill": {
     "duration": 0.020494,
     "end_time": "2024-03-11T21:41:31.850393",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.829899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 367 µs, sys: 60 µs, total: 427 µs\n",
      "Wall time: 1.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Making sklearn pipeline outputs as dataframe:-\n",
    "from sklearn import set_config;\n",
    "set_config(transform_output = \"pandas\");\n",
    "pd.set_option('display.max_columns', 50);\n",
    "pd.set_option('display.max_rows', 50);\n",
    "pd.set_option('display.precision', 3);\n",
    "\n",
    "# Setting global configurations for polars:-\n",
    "pl.Config.activate_decimals(True).set_tbl_hide_column_data_types(True);\n",
    "pl.Config(**dict(tbl_formatting = 'ASCII_FULL_CONDENSED',\n",
    "                 tbl_hide_column_data_types = True,\n",
    "                 tbl_hide_dataframe_shape = True,\n",
    "                 fmt_float = \"mixed\",\n",
    "                 tbl_cell_alignment = 'CENTER',\n",
    "                 tbl_hide_dtype_separator = True,\n",
    "                 tbl_cols = 100,\n",
    "                 tbl_rows = 50,\n",
    "                 fmt_str_lengths = 100,\n",
    "                )\n",
    "         );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07911106",
   "metadata": {
    "id": "QHuPn9_1ef6k",
    "papermill": {
     "duration": 0.008489,
     "end_time": "2024-03-11T21:41:31.867463",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.858974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:120%; text-align:left;padding:3.0px; background: #b32d00; border-bottom: 8px solid black\" > INTRODUCTION<br> <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5977dd",
   "metadata": {
    "papermill": {
     "duration": 0.009206,
     "end_time": "2024-03-11T21:41:31.884860",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.875654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2.1\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > UTILITIES<br><div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84f542e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:31.902950Z",
     "iopub.status.busy": "2024-03-11T21:41:31.902673Z",
     "iopub.status.idle": "2024-03-11T21:41:31.919322Z",
     "shell.execute_reply": "2024-03-11T21:41:31.918403Z"
    },
    "id": "E6nu1Zaueqdd",
    "outputId": "5cfb87db-db47-4d2f-f4b2-c8d26c696bd7",
    "papermill": {
     "duration": 0.028833,
     "end_time": "2024-03-11T21:41:31.921801",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.892968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 71 µs, sys: 12 µs, total: 83 µs\n",
      "Wall time: 86.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class Utility:\n",
    "    \"\"\"\n",
    "    This class serves to do the below-\n",
    "    1. Define method to print in color\n",
    "    2. Define the classifier metric, custom scorer callable and competition metrics\n",
    "    3. Define the garbage cleaning process\n",
    "    4. Define the predict-in-batch method to prevent OOM issues\n",
    "    \"\"\";\n",
    "\n",
    "    def PrintColor(self,text:str, color = Fore.BLUE, style = Style.BRIGHT):\n",
    "        \"Prints color outputs using colorama using a text F-string\";\n",
    "        print(style + color + text + Style.RESET_ALL);\n",
    "\n",
    "    def ScoreMetric(self, ytrue:np.array, ypred: np.array)-> float:\n",
    "        \"\"\"\n",
    "        This method calculates the classifier metric to evaluate the base-model\n",
    "        Inputs- ytrue, ypred:- np.array - input true and predictions arrays\n",
    "        Output- float:- base classifier metric, here- GINI score\n",
    "        \"\"\";\n",
    "        return roc_auc_score(ytrue, ypred);\n",
    "\n",
    "    def StabilityMetric(self, base, w_fallingrate=88.0, w_resstd=-0.5, week_lbl = \"WEEK_NUM\"):\n",
    "        \"\"\"\n",
    "        This method defines the GINI-stability metric as required for the competition\n",
    "        Source:- https://www.kaggle.com/code/darynarr/home-credit-drop-date-features\n",
    "        \"\"\";\n",
    "\n",
    "        grp_gini = \\\n",
    "        base.loc[:, [week_lbl, \"target\", \"score\"]].\\\n",
    "        sort_values(week_lbl).\\\n",
    "        groupby(week_lbl)[[\"target\", \"score\"]].\\\n",
    "        apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist();\n",
    "\n",
    "        x         = np.arange(len(grp_gini));\n",
    "        y         = grp_gini;\n",
    "        a, b      = np.polyfit(x, y, 1);\n",
    "        y_hat     = a*x + b;\n",
    "        residuals = y - y_hat;\n",
    "        res_std   = np.std(residuals);\n",
    "        avg_gini  = np.mean(gini_in_time);\n",
    "\n",
    "        return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std;\n",
    "\n",
    "    def CleanMemory(self):\n",
    "        \"This method cleans the memory off unused objects and displays the cleaned state RAM usage\";\n",
    "\n",
    "        collect();\n",
    "        libc.malloc_trim(0);\n",
    "        pid        = getpid();\n",
    "        py         = Process(pid);\n",
    "        memory_use = py.memory_info()[0] / 2. ** 30;\n",
    "        return f\"\\nRAM usage = {memory_use :.4} GB\";\n",
    "    \n",
    "    def PredictBatch(self, model, X: pd.DataFrame, prd_proba_req: bool = True, batch_size: int = 1000)-> np.array:\n",
    "        \"\"\"\n",
    "        This method predicts from the model in batches instead of the complete test set to avoid OOM issues in the test set\n",
    "        Inputs:-\n",
    "        1. X:- Train/ Test set\n",
    "        2. prd_proba_req:- need predict proba/ predictions- True [predict_proba], False[predict]\n",
    "        3. batch_size:- batch size to consider in one attempt\n",
    "\n",
    "        Returns:-\n",
    "        preds:- array of predicted probabilities\n",
    "        \"\"\";\n",
    "\n",
    "        num_samples = len(X);\n",
    "        num_batches = int(np.ceil(num_samples / batch_size));\n",
    "        preds       = np.zeros((num_samples,));\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            self.PrintColor(f\"---> Processing batch: {batch_idx+1}/{num_batches}\", color = Fore.CYAN);\n",
    "\n",
    "            start_idx = batch_idx * batch_size;\n",
    "            end_idx   = min((batch_idx + 1) * batch_size, num_samples);\n",
    "            X_batch   = X.iloc[start_idx : end_idx];\n",
    "\n",
    "            if prd_proba_req == True:\n",
    "                batch_probs = model.predict_proba(X_batch)[:, 1];\n",
    "            else:\n",
    "                batch_probs = model.predict(X_batch).data.squeeze();\n",
    "\n",
    "            preds[start_idx: end_idx] = batch_probs;\n",
    "            _ = self.CleanMemory();\n",
    "\n",
    "        return preds;\n",
    "    \n",
    "Utils = Utility();\n",
    "print();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7412457",
   "metadata": {
    "papermill": {
     "duration": 0.008115,
     "end_time": "2024-03-11T21:41:31.938364",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.930249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2.2\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > FOREWORD<br><div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77ce3a",
   "metadata": {
    "id": "kfzaZAxYeudt",
    "papermill": {
     "duration": 0.008268,
     "end_time": "2024-03-11T21:41:31.955410",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.947142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data columns**<br>\n",
    "This is available in the original data description as below<br>\n",
    "https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/data <br>\n",
    "<br>**Competition details and notebook objectives**<br>\n",
    "1. This is a binary classification challenge to predict home loan credit defaulters. **GINI** is the metric for the base classifier in this challenge<br>\n",
    "2. We also have to additionally assess the stability of GINI measure across time in the evaluation period. We need to score the classifier on a weekly basis and then assess the stability of the weekly GINI score using a regression model against time. Stability measure penalizes models that wane off in prediction capabilities across time. <br>\n",
    "2. In this starter notebook, we start the assignment with a simple preprocessing, understanding the data structure of the competition data, basic feature emgineering and develop starter models to initiate the challenge. We will also incorporate other opinions and approaches as we move along the challenge.<br>\n",
    "<br>\n",
    "**Model strategy** <br>\n",
    "We start off with simple tree based ML models and a soft-voting ensemble with appropriate inference in the test set submission. \n",
    "\n",
    "<br>**Kernel and method strategy**<br>\n",
    "1. We start off with a simple data transformer class that prepares the secondary features for the challenge. Considering the large size of the data, managing these tables within the confines of a Kaggle notebook environment will be a challenge, especially for model training <br> \n",
    "2. We verify the correctness of the data processor class on the train and test datasets, keeping track of execution time and memory usage too <br>\n",
    "3. We then train ML models here using similar but slightly varying parameters and then blend them using heuristic weights. <br>\n",
    "4. To prevent a deluge of tables and model objects in the inference pipeline, we synthesize an inherited voting classifier from each model, intaking the fold level model objects as inputs. These objects will be fed into the inference kernel and a combined prediction will be created <br>\n",
    "5. Training kernel is placed [here](https://www.kaggle.com/code/ravi20076/homecredit-starter-training-v1) for perusal and possible replication <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328e494",
   "metadata": {
    "id": "6Wd7_p60e2BS",
    "papermill": {
     "duration": 0.008096,
     "end_time": "2024-03-11T21:41:31.971822",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.963726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2.3\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > CONFIGURATION<br><div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4fe5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:31.990498Z",
     "iopub.status.busy": "2024-03-11T21:41:31.989679Z",
     "iopub.status.idle": "2024-03-11T21:41:32.117460Z",
     "shell.execute_reply": "2024-03-11T21:41:32.116411Z"
    },
    "id": "arG4DFTAe6By",
    "outputId": "bae5bb4b-c60d-4eac-94cf-dbfe9e206302",
    "papermill": {
     "duration": 0.139429,
     "end_time": "2024-03-11T21:41:32.119549",
     "exception": false,
     "start_time": "2024-03-11T21:41:31.980120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[34m--> Configuration done!\u001b[0m\n",
      "\u001b[1m\u001b[34m--> Sum of blend weights = 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "RAM usage = 0.3168 GB\u001b[0m\n",
      "CPU times: user 118 ms, sys: 764 µs, total: 119 ms\n",
      "Wall time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Configuration class:-\n",
    "class CFG:\n",
    "    \"\"\"\n",
    "    Configuration class for parameters and CV strategy for tuning and training\n",
    "    \"\"\";\n",
    "    \n",
    "    exp_nb             = 1;\n",
    "    version_nb         = 1;\n",
    "    test_req           = \"N\";\n",
    "    test_sample_frac   = 0.025;\n",
    "    state              = 42;\n",
    "    target             = 'target';\n",
    "    train_path         = \"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/train\";\n",
    "    test_path          = \"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/test\";\n",
    "    path               = \"/kaggle/input/home-credit-credit-risk-model-stability\";\n",
    "    model_path         = \"/kaggle/input/homecreditquality2024ancillary\";\n",
    "    null_cutoff        = 0.95;\n",
    "    cat_cutoff         = 200;\n",
    "    n_splits           = 3 if test_req == \"Y\" else 5;\n",
    "    n_repeats          = 1 ;\n",
    "    nbrnd_erly_stp     = 100;\n",
    "    all_exp_nb         = [\"E2V1\", \"E2V2\", \"E2V3\", \"E2V5\"];\n",
    "    myml_inner_wgt     = [0.80, 0.10, 0.10];\n",
    "    mymdl_wgt          = [0.10, 0.15, 0.20, 0.50];\n",
    "    blend_wgt          = [0.70, 0.15, 0.15];\n",
    "\n",
    "    # Global variables for plotting:-\n",
    "    grid_specs = {'visible': True, 'which': 'both', 'linestyle': '--',\n",
    "                  'color': 'lightgrey', 'linewidth': 0.75\n",
    "                  };\n",
    "    title_specs = {'fontsize': 9, 'fontweight': 'bold', 'color': 'tab:blue'};\n",
    "\n",
    "print();\n",
    "Utils.PrintColor(f\"--> Configuration done!\");\n",
    "Utils.PrintColor(f\"--> Sum of blend weights = {sum(CFG.blend_wgt):.2f}\");\n",
    "\n",
    "_ = Utils.PrintColor(Utils.CleanMemory());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b9e6e",
   "metadata": {
    "id": "NAQewn1YfIOR",
    "papermill": {
     "duration": 0.008479,
     "end_time": "2024-03-11T21:41:32.137192",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.128713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2.4\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > SUBMISSION HISTORY<br><div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980b891",
   "metadata": {
    "id": "0RF4jfQsfLli",
    "papermill": {
     "duration": 0.00827,
     "end_time": "2024-03-11T21:41:32.154198",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.145928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "|Experiment <br> Number|Version|Details|Features| Models|CV score|Stability score| Public LB score|\n",
    "|:-:|:-:|---|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|* Used my previous work including LGBM and LAMA models <br> * Aggregated experiments 2.1-2.6 |325-512|LGBM x 5||||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7e08a",
   "metadata": {
    "id": "OPIsksRgfR9C",
    "papermill": {
     "duration": 0.008464,
     "end_time": "2024-03-11T21:41:32.171552",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.163088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:120%; text-align:left;padding:3.0px; background: #b32d00; border-bottom: 8px solid black\" > PREPROCESSING<br> <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a326361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:32.190965Z",
     "iopub.status.busy": "2024-03-11T21:41:32.190621Z",
     "iopub.status.idle": "2024-03-11T21:41:32.355966Z",
     "shell.execute_reply": "2024-03-11T21:41:32.354868Z"
    },
    "id": "hucjcQeFfXER",
    "outputId": "75109759-7856-4f82-c918-0667d8e9dbd1",
    "papermill": {
     "duration": 0.177796,
     "end_time": "2024-03-11T21:41:32.358238",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.180442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "RAM usage = 0.3173 GB\u001b[0m\n",
      "CPU times: user 119 ms, sys: 659 µs, total: 119 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class DataXformer:\n",
    "    \"\"\"\n",
    "    This is a comprehensive preprocessing and data transformer class that does the below-\n",
    "    1. consumes the input data tables\n",
    "    2. creates secondary features\n",
    "    3. ensues memory efficient outputs for the model\n",
    "    \"\"\";\n",
    "\n",
    "    def __init__(self, null_cutoff: float, cat_cutoff: int,\n",
    "                 TrainTest: str      = \"test\",\n",
    "                 sel_cols: list      = [],\n",
    "                 cat_cols: list      = [],\n",
    "                 **kwarg\n",
    "                 ):\n",
    "\n",
    "        self.TrainTest   = TrainTest;\n",
    "        self.null_cutoff = null_cutoff;\n",
    "        self.cat_cutoff  = cat_cutoff;\n",
    "        self.target      = CFG.target;\n",
    "        self.sel_cols    = sel_cols;\n",
    "        self.cat_cols    = cat_cols;\n",
    "\n",
    "        if self.TrainTest == \"train\":\n",
    "            self.path = CFG.train_path;\n",
    "        else:\n",
    "            self.path = CFG.test_path;\n",
    "\n",
    "        Utils.PrintColor(f\"\\n{'='*10} {self.TrainTest.upper()} MODE {'='*10}\\n\", color = Fore.RED);\n",
    "\n",
    "    def _TypeCastCols(self, df: pl.DataFrame):\n",
    "        \"\"\"\n",
    "        This method casts the columns into the desired dtypes with basic date handling too\n",
    "        Input- df- pl.DataFrame:- input data table\n",
    "        Output- df:- pl.DataFrame:- dataframe with type-casting\n",
    "        \"\"\";\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64));\n",
    "            elif col in [\"date_decision\"] or col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date));\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64));\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String));\n",
    "\n",
    "        return df;\n",
    "\n",
    "    def _MakeDtFtre(self, df: pl.DataFrame):\n",
    "        \"\"\"\n",
    "        This method creates date features from the provided dataframe\n",
    "        Input- df- pl.DataFrame:- input data table\n",
    "        Output- df- pl.DataFrame:- dataframe with date column FE\n",
    "        \"\"\";\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col.endswith(\"D\"):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"));\n",
    "                df = df.with_columns(pl.col(col).dt.total_days());\n",
    "                df = df.with_columns([pl.col(\"date_decision\").dt.month().alias(\"month_nb\").cast(pl.Int8),\n",
    "                                      pl.col(\"date_decision\").dt.weekday().alias(\"weekday_nb\").cast(pl.Int8),\n",
    "                                     ]\n",
    "                                    );\n",
    "        return df.drop(\"date_decision\", \"MONTH\");\n",
    "\n",
    "    def _MakeAgg(self, df: pl.DataFrame):\n",
    "        \"\"\"\n",
    "        This method makes a set of aggregate expressions for group by on case id for depth > 0 tables\n",
    "\n",
    "        Note:-\n",
    "        1. We make [max, min, first, last] aggregations for all columns\n",
    "        2. We make mean aggregation for columns ending with [P, A, D]\n",
    "        3. We make mode aggregations for columns ending with [M]\n",
    "\n",
    "        Input - df- pl.DataFrame:- input data table\n",
    "        Output- all_agg:- list of aggregate expressions to be used with group_by case_id\n",
    "        \"\"\";\n",
    "\n",
    "        all_agg = [];\n",
    "        df_cols = df.columns;\n",
    "\n",
    "        all_agg.extend([method(col).alias(f\"{method.__name__}_{col}\") \\\n",
    "                        for method in [pl.max, pl.min, pl.first, pl.last] \\\n",
    "                        for col in df_cols if col[-1] in (\"P\", \"A\", \"D\", \"M\", \"T\", \"L\") or \"num_group\" in col\n",
    "                        ]\n",
    "                       );\n",
    "        all_agg.extend([pl.col(col).mean().alias(f\"mean_{col}\") for col in df_cols if col.endswith((\"P\", \"A\", \"D\"))]);\n",
    "        all_agg.extend([pl.col(col).drop_nulls().mode().first().alias(f\"mode_{col}\") for col in df_cols if col.endswith(\"M\")]);\n",
    "        return df.group_by(\"case_id\").agg(all_agg);\n",
    "\n",
    "    def _PreProcessIpTbl(self, path:str, depth: int, isSingle: bool, **kwarg):\n",
    "        \"\"\"\n",
    "        This method does the below-\n",
    "        1. Creates chunks for file loads if we have multiple files (isSingle = False)\n",
    "        2. Concatenates the chunks to a single file with typecasting\n",
    "        3. Aggregating on case id for depth > 0 tables\n",
    "        \"\"\";\n",
    "\n",
    "        if isSingle == False:\n",
    "            components = [];\n",
    "            for path in glob(str(path)):\n",
    "                components.append(pl.scan_parquet(path).pipe(self._TypeCastCols));\n",
    "            df = pl.concat(components, how = \"vertical_relaxed\");\n",
    "        else:\n",
    "            df = pl.scan_parquet(path).pipe(self._TypeCastCols);\n",
    "\n",
    "        if depth > 0:\n",
    "            return df.pipe(self._MakeAgg);\n",
    "        else:\n",
    "            return df;\n",
    "\n",
    "    @staticmethod\n",
    "    def _ReduceMem(df: pd.DataFrame):\n",
    "        \"This method reduces memory for numeric columns in the dataframe\";\n",
    "\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', \"uint16\", \"uint32\", \"uint64\"];\n",
    "        start_mem = df.memory_usage().sum() / 1024**2;\n",
    "\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtypes\n",
    "\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min();\n",
    "                c_max = df[col].max();\n",
    "\n",
    "                if \"int\" in str(col_type):\n",
    "                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min >= np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min >= np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min >= np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min >= np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    if c_min >= np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        end_mem = df.memory_usage().sum() / 1024**2;\n",
    "\n",
    "        Utils.PrintColor(f\"Start - end memory:- {start_mem:5.2f} - {end_mem:5.2f} Mb\");\n",
    "        return df;\n",
    "\n",
    "    def _MakeModelData(self, df_base, depth_0, depth_1, depth_2, **kwarg):\n",
    "        \"\"\"\n",
    "        This method aggregates the input tables and joins them to make a single model table for the next steps\n",
    "        It converts the final table to a pandas dataframe for the next steps, reduces the memory consumption and selects relevant columns\n",
    "        \"\"\";\n",
    "\n",
    "        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "            df_base = df_base.join(df, how = \"left\", on = \"case_id\", suffix = f\"_{i}\");\n",
    "        df = df_base.pipe(self._MakeDtFtre);\n",
    "        \n",
    "        if self.TrainTest.lower() == \"train\":\n",
    "            df = df.collect().to_pandas();\n",
    "            df = self._ReduceMem(df.replace([np.inf, -1*np.inf], np.NaN));\n",
    "            Utils.PrintColor(f\"---> Selecting training columns by nulls and category unique values\",\n",
    "                             color = Fore.CYAN\n",
    "                             );\n",
    "\n",
    "            drop_cols = [];\n",
    "            null_cols = df.drop(columns = [self.target], errors = \"ignore\").isna().mean();\n",
    "            drop_cols.extend(null_cols.loc[null_cols >= self.null_cutoff].index.to_list());\n",
    "\n",
    "            obj_cols = df.select_dtypes(include = \"object\").columns;\n",
    "            for col in obj_cols:\n",
    "                if df[col].nunique() >= self.cat_cutoff or df[col].nunique() == 1:\n",
    "                    drop_cols.append(col);\n",
    "            cat_cols  = [c for c in obj_cols if c not in drop_cols];\n",
    "\n",
    "            df = df.drop(columns = drop_cols, errors = \"ignore\");\n",
    "            df[cat_cols] = df[cat_cols].astype(\"category\");\n",
    "\n",
    "        else:\n",
    "            Utils.PrintColor(f\"---> Selecting all the test set columns to filter later\");\n",
    "        return df;\n",
    "\n",
    "    def XformData(self, display_store: bool = False):\n",
    "        \"\"\"\n",
    "        This is the cynosure method that aggregates all the inputs and prepares the FE dataset for the model training/ submission\n",
    "        \"\"\";\n",
    "\n",
    "        data_store = \\\n",
    "         {\"df_base\" : self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_base.parquet\"), depth = 0, isSingle = True),\n",
    "\n",
    "          \"depth_0\" : [self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_static_cb_0.parquet\"), depth = 0, isSingle = True),\n",
    "                       self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_static_0_*.parquet\"), depth = 0, isSingle = False)\n",
    "                      ],\n",
    "\n",
    "          \"depth_1\": [self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_applprev_1_*.parquet\"), depth = 1, isSingle = False),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_tax_registry_a_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_tax_registry_b_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_tax_registry_c_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_credit_bureau_b_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_other_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_person_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_deposit_1.parquet\"), depth = 1, isSingle = True),\n",
    "                      self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_debitcard_1.parquet\"), depth = 1, isSingle = True)\n",
    "                      ],\n",
    "\n",
    "          \"depth_2\": [self._PreProcessIpTbl(os.path.join(self.path, f\"{self.TrainTest}_credit_bureau_b_2.parquet\"), depth = 2, isSingle = True)]\n",
    "          };\n",
    "\n",
    "        if display_store:\n",
    "            Utils.PrintColor(\"\\n---> Data store\\n\", color = Fore.CYAN);\n",
    "            pprint(data_store, width = 200, depth = 3, indent = 5);\n",
    "\n",
    "        df = self._MakeModelData(**data_store);\n",
    "        del data_store;\n",
    "\n",
    "        if self.TrainTest.lower() == \"train\":\n",
    "            Utils.PrintColor(f\"\\n---> {self.TrainTest.capitalize()} set details = {df.shape} | {df.memory_usage().sum()/ 10**6 :,.2f} Mb\\n\",\n",
    "                         color = Fore.CYAN\n",
    "                         );\n",
    "            Utils.PrintColor(\"\\n---> Train set columns\\n\");\n",
    "            with np.printoptions(linewidth = 160):\n",
    "                pprint(np.array(df.drop(columns = [self.target], errors = \"ignore\").columns));\n",
    "\n",
    "                Utils.PrintColor(\"\\n---> Train set category columns\\n\", color = Fore.CYAN);\n",
    "                pprint(np.array(df.select_dtypes(include = \"category\").columns));\n",
    "        else:\n",
    "            pass;\n",
    "        return df;\n",
    "\n",
    "Utils.PrintColor(Utils.CleanMemory());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab340360",
   "metadata": {
    "id": "-htSH8n28ORa",
    "papermill": {
     "duration": 0.008665,
     "end_time": "2024-03-11T21:41:32.376091",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.367426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:120%; text-align:left;padding:3.0px; background: #b32d00; border-bottom: 8px solid black\" > MODEL INFERENCING<br> <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb3ca0",
   "metadata": {
    "papermill": {
     "duration": 0.008812,
     "end_time": "2024-03-11T21:41:32.393633",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.384821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4.1\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > ML MODELS<br><div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e76000c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:32.412567Z",
     "iopub.status.busy": "2024-03-11T21:41:32.412277Z",
     "iopub.status.idle": "2024-03-11T21:41:32.420282Z",
     "shell.execute_reply": "2024-03-11T21:41:32.419361Z"
    },
    "papermill": {
     "duration": 0.02006,
     "end_time": "2024-03-11T21:41:32.422651",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.402591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 µs, sys: 35 µs, total: 258 µs\n",
      "Wall time: 262 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class VotingModelMaker(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    This class prepares a voting model from the individual fold level contributions\n",
    "    Source - https://www.kaggle.com/code/greysky/home-credit-baseline\n",
    "    \"\"\";\n",
    "\n",
    "    def __init__(self, estimators: list):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self;\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0);\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5151aff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:32.441262Z",
     "iopub.status.busy": "2024-03-11T21:41:32.440944Z",
     "iopub.status.idle": "2024-03-11T21:41:48.845425Z",
     "shell.execute_reply": "2024-03-11T21:41:48.844268Z"
    },
    "papermill": {
     "duration": 16.416372,
     "end_time": "2024-03-11T21:41:48.847630",
     "exception": false,
     "start_time": "2024-03-11T21:41:32.431258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m\n",
      "========== TEST MODE ==========\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[34m---> Selecting all the test set columns to filter later\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "\n",
      "---> All files in the input path\n",
      "\u001b[0m\n",
      "array(['VC_E2V3_LGBM1C.model', 'VC_V1_LGBM1C.model', 'VC_E2V3_LGBM2C.model', 'SelCatCols_E2V5.pkl', 'SelCols_E2V1.pkl', 'VC_E2V4_LGBM2C.model',\n",
      "       'VC_E2V1_LGBM1C.model', 'VC_E1V2_LGBM4C.model', 'E2V6_DENSELIGHT.model', 'SelCatCols_E2V3.pkl', 'VC_E1V2_LGBM5C.model', 'VC_E1V2_LGBM3C.model',\n",
      "       'VC_E2V3_XGB1C.model', 'VC_E1V2_LGBM2C.model', 'VC_E1V4_XGB2C.model', 'VC_E2V4_XGB1C.model', 'VC_E2V5_LGBM1C.model', 'VC_E1V4_XGB5C.model',\n",
      "       'VC_E2V5_XGB1C.model', 'VC_E2V5_LGBM4C.model', 'SelCols_E2V2.pkl', 'SelCatCols_E2V4.pkl', 'VC_V1_LGBM3C.model', 'VC_E1V3_LGBM4C.model',\n",
      "       'VC_E1V3_LGBM1C.model', 'VC_V1_LGBM4C.model', 'E2V5_DENSELIGHT.model', 'VC_E1V2_LGBM1C.model', 'SelCatCols_E2V1.pkl', 'VC_E2V1_XGB1C.model',\n",
      "       'VC_E2V1_LGBM2C.model', 'SelCols_E2V5.pkl', 'VC_E2V2_XGB1C.model', 'VC_E2V5_LGBM2C.model', 'SelCols_E2V3.pkl', 'SelCatCols_E2V6.pkl',\n",
      "       'VC_E1V3_LGBM3C.model', 'VC_E2V5_LGBM3C.model', 'VC_E2V4_LGBM1C.model', 'VC_V1_LGBM2C.model', 'SelCatCols_E2V2.pkl', 'VC_V1_LGBM5C.model',\n",
      "       'SelCols_E2V6.pkl', 'VC_E1V3_LGBM5C.model', 'VC_E1V4_XGB4C.model', 'VC_E2V2_LGBM1C.model', 'SelCols_E2V4.pkl', 'VC_E2V2_LGBM2C.model',\n",
      "       'VC_E1V3_LGBM2C.model', 'VC_E1V4_XGB3C.model', 'VC_E1V4_XGB1C.model'], dtype='<U21')\n",
      "\u001b[1m\u001b[34m---> Current experiment = E2V1\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.02 -  0.02 Mb\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "---> ['VC_E2V1_LGBM1C.model', 'VC_E2V1_LGBM2C.model', 'VC_E2V1_XGB1C.model'] | Data shape = (10, 323)\u001b[0m\n",
      "\n",
      "VC_E2V1_LGBM1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V1_LGBM2C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V1_XGB1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "\u001b[1m\u001b[34m---> Current experiment = E2V2\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.03 -  0.02 Mb\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "---> ['VC_E2V2_LGBM1C.model', 'VC_E2V2_LGBM2C.model', 'VC_E2V2_XGB1C.model'] | Data shape = (10, 398)\u001b[0m\n",
      "\n",
      "VC_E2V2_LGBM1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V2_LGBM2C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V2_XGB1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "\u001b[1m\u001b[34m---> Current experiment = E2V3\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.03 -  0.02 Mb\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "---> ['VC_E2V3_LGBM1C.model', 'VC_E2V3_LGBM2C.model', 'VC_E2V3_XGB1C.model'] | Data shape = (10, 420)\u001b[0m\n",
      "\n",
      "VC_E2V3_LGBM1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V3_LGBM2C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V3_XGB1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "\u001b[1m\u001b[34m---> Current experiment = E2V5\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.04 -  0.03 Mb\u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "---> ['VC_E2V5_LGBM1C.model', 'VC_E2V5_LGBM2C.model', 'VC_E2V5_LGBM3C.model', 'VC_E2V5_LGBM4C.model', 'VC_E2V5_XGB1C.model'] | Data shape = (10, 500)\u001b[0m\n",
      "\n",
      "VC_E2V5_LGBM1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V5_LGBM2C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V5_LGBM3C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V5_LGBM4C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "VC_E2V5_XGB1C.model\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "CPU times: user 16.5 s, sys: 703 ms, total: 17.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Creating the test set features:-\n",
    "sub_fl = pd.read_csv(os.path.join(CFG.path, \"sample_submission.csv\"));\n",
    "\n",
    "# Creating output dataframe for model predictions:-\n",
    "Mdl_Preds = pd.DataFrame(index = range(len(sub_fl)));\n",
    "\n",
    "pp = DataXformer(TrainTest   = \"test\",\n",
    "                 null_cutoff = CFG.null_cutoff,\n",
    "                 cat_cutoff  = CFG.cat_cutoff,\n",
    "                 sel_cols    = [],\n",
    "                 cat_cols    = [],\n",
    "                );\n",
    "Xtest = pp.XformData(display_store = False);\n",
    "_ = Utils.CleanMemory();\n",
    "\n",
    "with np.printoptions(linewidth = 160):\n",
    "    Utils.PrintColor(f\"\\n\\n---> All files in the input path\\n\");\n",
    "    for _, _, files in os.walk(CFG.model_path):\n",
    "        pprint(np.array(files));\n",
    "        \n",
    "# Creating output structure for my models:-     \n",
    "MyMdl_Preds = pd.DataFrame(index = sub_fl.index);\n",
    "\n",
    "for exp_nb in CFG.all_exp_nb:\n",
    "    Utils.PrintColor(f\"---> Current experiment = {exp_nb}\");\n",
    "    cat_cols = joblib.load(os.path.join(CFG.model_path, f\"SelCatCols_{exp_nb}.pkl\")).to_list();\n",
    "    sel_cols = joblib.load(os.path.join(CFG.model_path, f\"SelCols_{exp_nb}.pkl\")).to_list();\n",
    "    \n",
    "    Xt = pp._ReduceMem(Xtest.select(sel_cols).\\\n",
    "                       collect().\\\n",
    "                       to_pandas().\\\n",
    "                       drop(columns = [\"WEEK_NUM\", \"case_id\"], errors = \"ignore\")\n",
    "                      );\n",
    "    Xt[cat_cols] = Xt[cat_cols].astype(\"category\");\n",
    "    \n",
    "    model_files = \\\n",
    "    sorted([f for f in files if f\"{exp_nb}\" in f and (\"LGBM\" in f or \"XGB\" in f) and f.endswith('.model')]);\n",
    "    Utils.PrintColor(f\"\\n---> {model_files} | Data shape = {Xt.shape}\", color = Fore.MAGENTA);\n",
    "    preds = pd.DataFrame(index = Mdl_Preds.index, columns = model_files);\n",
    "    \n",
    "    print();\n",
    "    for f in model_files:\n",
    "        print(f);\n",
    "        model    = joblib.load(os.path.join(CFG.model_path, f));\n",
    "        preds[f] = Utils.PredictBatch(model, Xt);\n",
    "    del Xt;\n",
    "    _ = Utils.CleanMemory();\n",
    "    \n",
    "    try:\n",
    "        MyMdl_Preds[exp_nb] = np.average(preds.values, axis=1, weights = CFG.myml_inner_wgt);\n",
    "    except:\n",
    "        MyMdl_Preds[exp_nb] = np.mean(preds.values, axis=1);\n",
    " \n",
    "Mdl_Preds[\"MyLGBM\"] = np.average(MyMdl_Preds.values, axis=1, weights = CFG.mymdl_wgt);\n",
    "del MyMdl_Preds;\n",
    "\n",
    "Utils.CleanMemory();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fbe32",
   "metadata": {
    "papermill": {
     "duration": 0.011433,
     "end_time": "2024-03-11T21:41:48.870608",
     "exception": false,
     "start_time": "2024-03-11T21:41:48.859175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4.2\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > LAMA DENSELIGHT MODEL<br><div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d746e189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:41:48.895364Z",
     "iopub.status.busy": "2024-03-11T21:41:48.895009Z",
     "iopub.status.idle": "2024-03-11T21:45:01.529106Z",
     "shell.execute_reply": "2024-03-11T21:45:01.528053Z"
    },
    "papermill": {
     "duration": 192.649398,
     "end_time": "2024-03-11T21:45:01.531576",
     "exception": false,
     "start_time": "2024-03-11T21:41:48.882178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m---> Selecting all the test set columns to filter later\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.04 -  0.03 Mb\u001b[0m\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[34m---> Selecting all the test set columns to filter later\u001b[0m\n",
      "\u001b[1m\u001b[34mStart - end memory:-  0.03 -  0.02 Mb\u001b[0m\n",
      "\u001b[1m\u001b[36m---> Processing batch: 1/1\u001b[0m\n",
      "CPU times: user 36.5 s, sys: 1.94 s, total: 38.4 s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "!pip install --no-index -Uq --find-links=/kaggle/input/lightautoml-038-dependencies lightautoml==0.3.8 -q;\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML;\n",
    "from lightautoml.tasks import Task;\n",
    "clear_output();\n",
    "\n",
    "model    = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/E2V5_DENSELIGHT.model\");\n",
    "sel_cols = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/SelCols_E2V5.pkl\");\n",
    "cat_cols = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/SelCatCols_E2V5.pkl\");\n",
    "Xtest    = pp.XformData(display_store = False);\n",
    "Xtest    = pp._ReduceMem(Xtest.select(sel_cols).collect().to_pandas());\n",
    "Xtest[cat_cols] = Xtest[cat_cols].astype(\"category\");\n",
    "Mdl_Preds[\"LAMA1\"] = Utils.PredictBatch(model, Xtest, prd_proba_req = False);\n",
    "del Xtest;\n",
    "_ = Utils.CleanMemory();\n",
    "\n",
    "print(\"\\n\\n\\n\");\n",
    "model    = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/E2V6_DENSELIGHT.model\");\n",
    "sel_cols = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/SelCols_E2V6.pkl\");\n",
    "cat_cols = joblib.load(\"/kaggle/input/homecreditquality2024ancillary/SelCatCols_E2V6.pkl\");\n",
    "Xtest    = pp.XformData(display_store = False);\n",
    "Xtest    = pp._ReduceMem(Xtest.select(sel_cols).collect().to_pandas());\n",
    "Xtest[cat_cols] = Xtest[cat_cols].astype(\"category\");\n",
    "Mdl_Preds[\"LAMA2\"] = Utils.PredictBatch(model, Xtest, prd_proba_req = False);\n",
    "del Xtest;\n",
    "_ = Utils.CleanMemory(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83038f",
   "metadata": {
    "papermill": {
     "duration": 0.011572,
     "end_time": "2024-03-11T21:45:01.554837",
     "exception": false,
     "start_time": "2024-03-11T21:45:01.543265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4.6\"></a>\n",
    "## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background:  #e0ebeb; border-bottom: 8px solid #b32d00\" > FINAL PREDICTIONS<br><div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188bf98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T21:45:01.579516Z",
     "iopub.status.busy": "2024-03-11T21:45:01.578837Z",
     "iopub.status.idle": "2024-03-11T21:45:02.170691Z",
     "shell.execute_reply": "2024-03-11T21:45:02.169578Z"
    },
    "papermill": {
     "duration": 0.606448,
     "end_time": "2024-03-11T21:45:02.172831",
     "exception": false,
     "start_time": "2024-03-11T21:45:01.566383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas = 2.2.0\n",
      "\u001b[1m\u001b[34m\n",
      "---> Model predictions across all options\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6760f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6760f_level0_col0\" class=\"col_heading level0 col0\" >MyLGBM</th>\n",
       "      <th id=\"T_6760f_level0_col1\" class=\"col_heading level0 col1\" >LAMA1</th>\n",
       "      <th id=\"T_6760f_level0_col2\" class=\"col_heading level0 col2\" >LAMA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6760f_row0_col0\" class=\"data row0 col0\" >0.0068</td>\n",
       "      <td id=\"T_6760f_row0_col1\" class=\"data row0 col1\" >0.0047</td>\n",
       "      <td id=\"T_6760f_row0_col2\" class=\"data row0 col2\" >0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6760f_row1_col0\" class=\"data row1 col0\" >0.0155</td>\n",
       "      <td id=\"T_6760f_row1_col1\" class=\"data row1 col1\" >0.0445</td>\n",
       "      <td id=\"T_6760f_row1_col2\" class=\"data row1 col2\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6760f_row2_col0\" class=\"data row2 col0\" >0.0064</td>\n",
       "      <td id=\"T_6760f_row2_col1\" class=\"data row2 col1\" >0.0037</td>\n",
       "      <td id=\"T_6760f_row2_col2\" class=\"data row2 col2\" >0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6760f_row3_col0\" class=\"data row3 col0\" >0.0135</td>\n",
       "      <td id=\"T_6760f_row3_col1\" class=\"data row3 col1\" >0.0063</td>\n",
       "      <td id=\"T_6760f_row3_col2\" class=\"data row3 col2\" >0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6760f_row4_col0\" class=\"data row4 col0\" >0.0946</td>\n",
       "      <td id=\"T_6760f_row4_col1\" class=\"data row4 col1\" >0.0577</td>\n",
       "      <td id=\"T_6760f_row4_col2\" class=\"data row4 col2\" >0.0518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6760f_row5_col0\" class=\"data row5 col0\" >0.0053</td>\n",
       "      <td id=\"T_6760f_row5_col1\" class=\"data row5 col1\" >0.0023</td>\n",
       "      <td id=\"T_6760f_row5_col2\" class=\"data row5 col2\" >0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6760f_row6_col0\" class=\"data row6 col0\" >0.0392</td>\n",
       "      <td id=\"T_6760f_row6_col1\" class=\"data row6 col1\" >0.0010</td>\n",
       "      <td id=\"T_6760f_row6_col2\" class=\"data row6 col2\" >0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6760f_row7_col0\" class=\"data row7 col0\" >0.0163</td>\n",
       "      <td id=\"T_6760f_row7_col1\" class=\"data row7 col1\" >0.0004</td>\n",
       "      <td id=\"T_6760f_row7_col2\" class=\"data row7 col2\" >0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6760f_row8_col0\" class=\"data row8 col0\" >0.1737</td>\n",
       "      <td id=\"T_6760f_row8_col1\" class=\"data row8 col1\" >0.0243</td>\n",
       "      <td id=\"T_6760f_row8_col2\" class=\"data row8 col2\" >0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6760f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6760f_row9_col0\" class=\"data row9 col0\" >0.0360</td>\n",
       "      <td id=\"T_6760f_row9_col1\" class=\"data row9 col1\" >0.0050</td>\n",
       "      <td id=\"T_6760f_row9_col2\" class=\"data row9 col2\" >0.0054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x78cb30f366e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "\n",
      "---> Final submission file\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>case_id</th><th>score</th></tr></thead><tbody><tr><td>0</td><td>57543</td><td>0.007135</td></tr><tr><td>1</td><td>57549</td><td>0.023253</td></tr><tr><td>2</td><td>57551</td><td>0.005239</td></tr><tr><td>3</td><td>57552</td><td>0.011468</td></tr><tr><td>4</td><td>57569</td><td>0.082646</td></tr><tr><td>5</td><td>57630</td><td>0.004405</td></tr><tr><td>6</td><td>57631</td><td>0.027925</td></tr><tr><td>7</td><td>57632</td><td>0.011522</td></tr><tr><td>8</td><td>57633</td><td>0.127886</td></tr><tr><td>9</td><td>57634</td><td>0.026719</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+-------+---------+----------+\n",
       "| index | case_id |   score  |\n",
       "+============================+\n",
       "|   0   |  57543  | 0.007135 |\n",
       "|   1   |  57549  | 0.023253 |\n",
       "|   2   |  57551  | 0.005239 |\n",
       "|   3   |  57552  | 0.011468 |\n",
       "|   4   |  57569  | 0.082646 |\n",
       "|   5   |  57630  | 0.004405 |\n",
       "|   6   |  57631  | 0.027925 |\n",
       "|   7   |  57632  | 0.011522 |\n",
       "|   8   |  57633  | 0.127886 |\n",
       "|   9   |  57634  | 0.026719 |\n",
       "+-------+---------+----------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 572 ms, sys: 5.85 ms, total: 578 ms\n",
      "Wall time: 584 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import pandas as pd;\n",
    "print(f\"Pandas = {pd.__version__}\");\n",
    "\n",
    "Utils.PrintColor(f\"\\n---> Model predictions across all options\\n\");\n",
    "display(Mdl_Preds.head(10).style.format(precision = 4));\n",
    "\n",
    "sub_fl[\"score\"] = np.average(Mdl_Preds.values, axis=1, weights = CFG.blend_wgt);\n",
    "\n",
    "del Mdl_Preds;\n",
    "_ = Utils.CleanMemory();\n",
    "\n",
    "sub_fl = pl.DataFrame(sub_fl.reset_index());  \n",
    "Utils.PrintColor(f\"\\n\\n---> Final submission file\\n\");\n",
    "display(sub_fl.head(10));\n",
    "\n",
    "# Saving the submission file for leaderboard:-\n",
    "sub_fl.select([\"case_id\", \"score\"]).write_csv(f\"submission.csv\",);     \n",
    "_ = Utils.CleanMemory(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c594c7",
   "metadata": {
    "papermill": {
     "duration": 0.011896,
     "end_time": "2024-03-11T21:45:02.197174",
     "exception": false,
     "start_time": "2024-03-11T21:45:02.185278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:120%; text-align:left;padding:3.0px; background: #b32d00; border-bottom: 8px solid black\" > PLANNED NEXT STEPS<br> <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c634c98",
   "metadata": {
    "papermill": {
     "duration": 0.011625,
     "end_time": "2024-03-11T21:45:02.221135",
     "exception": false,
     "start_time": "2024-03-11T21:45:02.209510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style= \"font-family: Cambria; letter-spacing: 0px; color:#000000; font-size:110%; text-align:left;padding:3.0px; background: #f2f2f2\" >\n",
    "1. We need to understand the data structure first. Exploring through all the files and understanding the columns is key<br>\n",
    "2. The importance of a good EDA cannot be described enough in words in such a challenge <br>\n",
    "3. Developing a better set of models with better feature choices is key <br>\n",
    "4. Understanding the stability metric and incorporating it in the training and inferencing pipeline is also key <br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "datasetId": 4422102,
     "sourceId": 7633217,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4256688,
     "sourceId": 7742446,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 161936385,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 162314401,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 162317063,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 162470947,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 293.339512,
   "end_time": "2024-03-11T21:45:04.896561",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-11T21:40:11.557049",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
