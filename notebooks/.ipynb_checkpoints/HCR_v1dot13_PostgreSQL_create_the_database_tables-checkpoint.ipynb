{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20200ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# import subprocess; command = \"yes | pip3.9 install psycopg2-binary --force-reinstall --no-cache-dir\"; subprocess.run(command, shell=True)\n",
    "result = subprocess.run(['pip3', 'install', 'ipython-autotime'], capture_output=True)\n",
    "print(f\"There was a problem installing the package.\\nError output:\\n{result.stderr.decode('utf-8')}\") if result.returncode != 0 else print(\"Package installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b10bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 Âµs (started: 2024-04-11 13:01:22 -07:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd31e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fbaa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/y4hv4_s9751293nzv4yrfrtm0000gn/T/ipykernel_24451/3623537554.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 870 ms (started: 2024-04-11 13:01:22 -07:00)\n"
     ]
    }
   ],
   "source": [
    "#Configuration\n",
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "#Python: File Input/Output\n",
    "from glob import glob #global - The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. Source: https://docs.python.org/3/library/glob.html\n",
    "\n",
    "\n",
    "#PostgreSQL: Setup; Data Analysis\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "\n",
    "\n",
    "#Python: Data Analysis\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d100c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99.9% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.configuration at 0x7fcc2a8410d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.28 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "'''Python: Notebook Configuration'''\n",
    "\n",
    "class configuration:\n",
    "    def __init__(self, train_data_directory_path=None, site_packages_directory=None):\n",
    "        \n",
    "        if train_data_directory_path == None:\n",
    "            self.train_data_directory_path = '/Users/pauljacob/MyDrive_pauljacob.datascience1@gmail.com/Projects/Home_Credit_Risk/data/raw/train/'\n",
    "        if site_packages_directory == None:\n",
    "            self.site_packages_directory = \"/Users/pauljacob/Library/Python/3.9/lib/python/site-packages\"\n",
    "            \n",
    "        self.set_the_site_packages_directory()\n",
    "        self.set_the_notebook_display_settings()\n",
    "        \n",
    "\n",
    "    def set_the_notebook_display_settings(self):\n",
    "        display(HTML(\"<style>.container { width:99.9% !important; }</style>\"))\n",
    "        pd.options.display.max_columns = 3999\n",
    "        pd.options.display.max_rows = 999\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        pd.options.display.max_info_columns = 3999\n",
    "\n",
    "    def set_the_site_packages_directory(self):\n",
    "        sys.path.append(self.site_packages_directory)\n",
    "        \n",
    "\n",
    "configuration = configuration()\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef98fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75842a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a5aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.06 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "'''Python: Data Input/Output'''\n",
    "\n",
    "def get_filename_path_list_from_filename_path_regular_expression(filename_path_regular_expression):\n",
    "    \n",
    "    filename_path_list = glob(str(filename_path_regular_expression))\n",
    "    filename_path_list.sort()\n",
    "    return filename_path_list\n",
    "\n",
    "\n",
    "def get_filename_list():\n",
    "    filename_list = [filename for filename in os.listdir(configuration.train_data_directory_path) if not filename in ['.DS_Store']]\n",
    "    filename_list.sort()\n",
    "    return filename_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''PostgreSQL: Setup'''\n",
    "\n",
    "def generate_parent_paths_from(filename_path):\n",
    "    components = filename_path.split(os.sep)\n",
    "    parent_paths = [os.sep.join(components[:i+1]) for i in range(len(components))]\n",
    "    return '/ '.join(parent_paths[2:])\n",
    "\n",
    "\n",
    "\n",
    "def create_connection(db_name, db_user, db_password, db_host, db_port):\n",
    "    '''Source: https://realpython.com/python-sql-libraries/#postgresql'''\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = psycopg2.connect(database=db_name, user=db_user, password=db_password, host=db_host, port=db_port,)\n",
    "        print(\"Connection to PostgreSQL DB successful\")\n",
    "    except OperationalError as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "    return connection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_the_column_name_list_from_table_name(table_name, connection,):\n",
    "\n",
    "    query = \"SELECT column_name FROM information_schema.columns WHERE table_name = '{}';\".format(table_name)\n",
    "    cur = connection.cursor()\n",
    "    cur.execute(query)\n",
    "    column_name_list = cur.fetchall()\n",
    "    cur.close()\n",
    "\n",
    "    return [row[0] for row in column_name_list]\n",
    "\n",
    "\n",
    "\n",
    "def execute_query(connection, query, table_name=None, column_name_list=None):\n",
    "    connection.autocommit = True\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query); print(\"Query executed successfully\")\n",
    "        if \"SELECT\" in query:\n",
    "            result=cursor.fetchall()\n",
    "            cursor.close()\n",
    "            if table_name != None and column_name_list != None:\n",
    "\n",
    "                df_list = [pd.DataFrame(result[0+offset:10000+offset]) for offset in range(0, len(result), 10000)]\n",
    "                df = pd.concat(df_list, axis=0)\n",
    "                df.columns=column_name_list\n",
    "                return df\n",
    "            \n",
    "            elif table_name != None and column_name_list == None:\n",
    "                column_name_list=get_the_column_name_list_from_table_name(table_name=table_name, connection=connection)\n",
    "                df_list = [pd.DataFrame(result[0+offset:10000+offset]) for offset in range(0, len(result), 10000)]\n",
    "                df = pd.concat(df_list, axis=0)\n",
    "                return df\n",
    "            \n",
    "            elif table_name == None:\n",
    "                df_list = [pd.DataFrame(result[0+offset:10000+offset]) for offset in range(0, len(result), 10000)]\n",
    "                if len(df_list) > 0:\n",
    "                    df=pd.concat(df_list, axis=0)\n",
    "                    return df\n",
    "                else:\n",
    "                    return None\n",
    "        else:\n",
    "            cursor.close()\n",
    "            return None\n",
    "\n",
    "    except OperationalError as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "\n",
    "\n",
    "def construct_query_from_table_name_column_name_list_and_data_type_list(table_name, column_name_list, data_type_list):\n",
    "\n",
    "    query = f\"CREATE TABLE {table_name} (\"\n",
    "\n",
    "    for column_name, data_type in zip(column_name_list, data_type_list):\n",
    "        query += f\"{column_name} {data_type}, \"\n",
    "\n",
    "    query = query[:-2]; query += \")\"\n",
    "    return query\n",
    "\n",
    "\n",
    "\n",
    "def create_and_copy_file_to_postgresql_table(table_name, column_name_list, data_type_list, filename_path_list):\n",
    "    \n",
    "    #Drop the Table if it Exists\n",
    "    query = \"DROP TABLE IF EXISTS {};\".format(table_name)\n",
    "    execute_query(connection, query=query, table_name=table_name, column_name_list=None)\n",
    "\n",
    "    #Construct and Execute the Create PostgreSQL Table Query\n",
    "    query=construct_query_from_table_name_column_name_list_and_data_type_list(table_name=table_name, column_name_list=column_name_list, data_type_list=data_type_list)\n",
    "    execute_query(connection=connection, query=query, table_name=table_name)\n",
    "\n",
    "    for filename_path in filename_path_list:\n",
    "        # Enable Read and Execute Permissions to the .csv File\n",
    "        filename_parent_paths=generate_parent_paths_from(filename_path=filename_path)\n",
    "        command = \"chmod a+rX {}\".format(filename_parent_paths); subprocess.run(command, shell=True)\n",
    "\n",
    "        #Copy the .csv Data into the Table\n",
    "        query = \"copy {} FROM '{}' DELIMITER ',' CSV HEADER;\".format(table_name, filename_path)\n",
    "        execute_query(connection=connection, query=query, table_name=table_name)\n",
    "        \n",
    "        \n",
    "def extract_database_table_data_type_list_from_dataframe(df):\n",
    "\n",
    "    dtype_list = list(df.dtypes.reset_index().rename(columns={'index':'name', 0:'values'}).loc[:, 'values'].values)\n",
    "    column_name_list = list(df.columns)\n",
    "\n",
    "    database_table_data_type_list = []\n",
    "    index = 0\n",
    "    for dtype, column_name in zip(dtype_list, column_name_list):\n",
    "        if dtype == 'int64':\n",
    "            database_table_data_type_list += ['INTEGER']\n",
    "            \n",
    "        elif (dtype == 'O') and (column_name[-1] in ['D',]):\n",
    "            database_table_data_type_list += ['DATE']\n",
    "            \n",
    "        elif (dtype == 'O') and ('date' in column_name):\n",
    "            database_table_data_type_list += ['DATE']\n",
    "            \n",
    "        elif (dtype == 'O') and (not 'date' in column_name) and (not column_name[-1] in ['D',]):\n",
    "            database_table_data_type_list += ['VARCHAR']\n",
    "            \n",
    "        elif (dtype == 'float64'):\n",
    "            database_table_data_type_list += ['NUMERIC']\n",
    "            \n",
    "        elif (dtype == 'bool'):\n",
    "            database_table_data_type_list += ['BOOLEAN']\n",
    "            \n",
    "    return database_table_data_type_list\n",
    "\n",
    "\n",
    "\n",
    "'''PostgreSQL: Data Analysis'''\n",
    "\n",
    "def get_the_table_column_values_and_value_counts(table_name, column_name):\n",
    "    #Print the Column Name 'approvaldate_319D' Value Counts\n",
    "    query=\\\n",
    "    \"SELECT {}, COUNT({}) AS value_count \\\n",
    "    FROM {} GROUP BY {} ORDER BY value_count DESC;\".format(column_name, column_name, table_name, column_name)\n",
    "    df_value_counts=execute_query(connection, query=query, table_name=table_name, column_name_list=[column_name, 'value_count'])\n",
    "    print(df_value_counts.head(20))\n",
    "\n",
    "    #Select the Values of Column Name 'annuity_853A'\n",
    "    query=\"SELECT {} FROM {}\".format(column_name, table_name)\n",
    "    return execute_query(connection, query=query, table_name=table_name, column_name_list=[column_name])\n",
    "\n",
    "\n",
    "def get_the_table_column_data_types_and_value_count(table_name, column_name, data_type):\n",
    "    #print the Data Type Count of Column Name ' '\n",
    "    query=\"SELECT pg_typeof({}) AS {}, COUNT(*) AS count FROM {} GROUP BY {};\".format(column_name, data_type, table_name, data_type)\n",
    "    data_type_value_count=execute_query(connection, query=query, table_name=table_name, column_name_list=[column_name, 'value_count'])\n",
    "    print(data_type_value_count)\n",
    "    \n",
    "    #Get the Data Type of Column Name ' '\n",
    "    query=\"SELECT pg_typeof({}) AS {} FROM {};\".format(column_name, data_type, table_name)\n",
    "    return execute_query(connection, query=query, table_name=table_name, column_name_list=[column_name])\n",
    "\n",
    "\n",
    "def create_database_table_and_return_dataframe_from_single_filename(filename, return_result=True):\n",
    "\n",
    "    #extract table_name from filename\n",
    "    table_name = filename.split('.csv')[0]\n",
    "\n",
    "    #extract data_type_list from .CSV file using pandas\n",
    "    df = pd.read_csv(configuration.train_data_directory_path + filename)\n",
    "    data_type_list = extract_database_table_data_type_list_from_dataframe(df=df)\n",
    "\n",
    "    #extract column_name_list\n",
    "    column_name_list = list(df.columns)\n",
    "    del df\n",
    "\n",
    "    filename_path_list = [f'{configuration.train_data_directory_path}{filename}']\n",
    "\n",
    "    create_and_copy_file_to_postgresql_table(table_name=table_name, column_name_list=column_name_list, data_type_list=data_type_list, filename_path_list=filename_path_list)\n",
    "\n",
    "    if return_result == False:\n",
    "        return None\n",
    "    else:\n",
    "        #read from the Database Table as a pandas DataFrame\n",
    "        query=f'SELECT * FROM {table_name}'\n",
    "        return execute_query(connection=connection, query=query, table_name=table_name, column_name_list=column_name_list)\n",
    "\n",
    "\n",
    "def create_database_table_and_return_dataframe_from_filename_regular_expression(filename_regular_expression, return_result=True):\n",
    "    \n",
    "    #get the filename_path_list\n",
    "    filename_path_list = get_filename_path_list_from_filename_path_regular_expression(configuration.train_data_directory_path+filename_regular_expression)\n",
    "\n",
    "\n",
    "    #extract table_name from filename\n",
    "    table_name = filename_regular_expression.split('_*.csv')[0]\n",
    "\n",
    "\n",
    "    #extract data_type_list from .CSV file using pandas\n",
    "    df_index_0 = pd.read_csv(filename_path_list[0])\n",
    "    data_type_list = extract_database_table_data_type_list_from_dataframe(df=df_index_0)\n",
    "\n",
    "\n",
    "    #extract column_name_list\n",
    "    column_name_list = list(df_index_0.columns)\n",
    "\n",
    "    del df_index_0\n",
    "\n",
    "    create_and_copy_file_to_postgresql_table(table_name=table_name, column_name_list=column_name_list, data_type_list=data_type_list, filename_path_list=filename_path_list)\n",
    "\n",
    "    if return_result == False:\n",
    "        return None\n",
    "    else:\n",
    "        #read from the Database Table as a pandas DataFrame\n",
    "        query=f'SELECT * FROM {table_name}'\n",
    "        return execute_query(connection=connection, query=query, table_name=table_name, column_name_list=column_name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e002daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d636ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 722 Âµs (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "'''Python: Utility Function'''\n",
    "\n",
    "def occupy_the_kernel():\n",
    "    time.sleep(1000000)\n",
    "\n",
    "    \n",
    "\n",
    "'''Python: Data Analysis'''\n",
    "\n",
    "def preview_df(df):\n",
    "    \"\"\"Of this DataFrame, prints the row and column count and then returns the concatenated first 5 and last % rows.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): This pandas DataFrame object.\n",
    "    Returns:\n",
    "        df (DataFrame): The concatenated first 5 and last 5 rows of this pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if df.shape[0] > 9:\n",
    "        print(df.shape)\n",
    "        return pd.DataFrame(pd.concat([df.head(5), df.tail(5)]))\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "def preview_list(list_):\n",
    "    \"\"\"Print the list length and return the list.\n",
    "    \n",
    "    Args:\n",
    "        list_ (list): The list object to return.\n",
    "    \n",
    "    Returns:\n",
    "        list_ (list): The same list object.\n",
    "    \"\"\"\n",
    "    print(len(list_))\n",
    "    return list_\n",
    "\n",
    "\n",
    "\n",
    "def filter_this_data_frame_by_column_name_and_value_list(df, column_name, value_list):\n",
    "    return df.loc[df.loc[:, column_name].isin(value_list), :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa889f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106c103f",
   "metadata": {},
   "source": [
    "### Connect to the Database 'postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77931cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL DB successful\n",
      "Query executed successfully\n",
      "The error 'cannot drop the currently open database\n",
      "' occurred\n",
      "Query executed successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>postgres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  postgres"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.9 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "#Create the Connection to the Database 'postgres'\n",
    "connection = create_connection(db_name=\"postgres\", db_user=\"postgres\", db_password=\"postgres\", db_host=\"127.0.0.1\", db_port=\"5432\")\n",
    "\n",
    "#Drop the Database 'database1' (if it Exists)\n",
    "query=\"DROP DATABASE IF EXISTS database1;\"\n",
    "execute_query(connection=connection, query=query)\n",
    "\n",
    "#Drop the Database 'postgres' (if it Exists)\n",
    "query=\"DROP DATABASE IF EXISTS postgres;\"\n",
    "execute_query(connection=connection, query=query)\n",
    "\n",
    "#Get the Database Names\n",
    "query=\"SELECT datname FROM pg_database WHERE datistemplate = false;\"\n",
    "execute_query(connection=connection, query=query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5dfe1",
   "metadata": {},
   "source": [
    "### Get the Table Names of the Database 'postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccb418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully\n",
      "time: 5.46 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "query=\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\"\n",
    "\n",
    "result=execute_query(connection, query=query, table_name=None, column_name_list=None)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a814e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 185 Âµs (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd994c",
   "metadata": {},
   "source": [
    "### Drop the Table Names of the Database 'postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797d44e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 438 Âµs (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "if result is not None:\n",
    "    table_name_list = [table_name[0] for table_name in result.values]\n",
    "\n",
    "    if len(table_name_list) > 0:\n",
    "        table_name_string = ', '.join(table_name_list)\n",
    "\n",
    "        table_name = table_name_string\n",
    "\n",
    "        #Drop the Table's if they Exist\n",
    "        query = \"DROP TABLE IF EXISTS {};\".format(table_name)\n",
    "        execute_query(connection, query=query, table_name=table_name, column_name_list=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bc8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully\n",
      "time: 1.56 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get the Table Name's\n",
    "query=\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\"\n",
    "result=execute_query(connection, query=query, table_name=None, column_name_list=None)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafb4259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_applprev_1_0.csv',\n",
       " 'train_applprev_1_1.csv',\n",
       " 'train_applprev_2.csv',\n",
       " 'train_base.csv',\n",
       " 'train_credit_bureau_a_1_0.csv',\n",
       " 'train_credit_bureau_a_1_1.csv',\n",
       " 'train_credit_bureau_a_1_2.csv',\n",
       " 'train_credit_bureau_a_1_3.csv',\n",
       " 'train_credit_bureau_a_2_0.csv',\n",
       " 'train_credit_bureau_a_2_1.csv',\n",
       " 'train_credit_bureau_a_2_10.csv',\n",
       " 'train_credit_bureau_a_2_2.csv',\n",
       " 'train_credit_bureau_a_2_3.csv',\n",
       " 'train_credit_bureau_a_2_4.csv',\n",
       " 'train_credit_bureau_a_2_5.csv',\n",
       " 'train_credit_bureau_a_2_6.csv',\n",
       " 'train_credit_bureau_a_2_7.csv',\n",
       " 'train_credit_bureau_a_2_8.csv',\n",
       " 'train_credit_bureau_a_2_9.csv',\n",
       " 'train_credit_bureau_b_1.csv',\n",
       " 'train_credit_bureau_b_2.csv',\n",
       " 'train_debitcard_1.csv',\n",
       " 'train_deposit_1.csv',\n",
       " 'train_other_1.csv',\n",
       " 'train_person_1.csv',\n",
       " 'train_person_2.csv',\n",
       " 'train_static_0_0.csv',\n",
       " 'train_static_0_1.csv',\n",
       " 'train_static_cb_0.csv',\n",
       " 'train_tax_registry_a_1.csv',\n",
       " 'train_tax_registry_b_1.csv',\n",
       " 'train_tax_registry_c_1.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.8 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "preview_list(get_filename_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f60a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb4f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657571bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_static_0_*.csv',\n",
       " 'train_applprev_1_*.csv',\n",
       " 'train_credit_bureau_a_1_*.csv',\n",
       " 'train_credit_bureau_a_2_*.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.03 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "filename_star_list = ['train_static_0_*.csv', 'train_applprev_1_*.csv', 'train_credit_bureau_a_1_*.csv', 'train_credit_bureau_a_2_*.csv']\n",
    "filename_single_list=['train_base.csv', 'train_static_cb_0.csv', 'train_tax_registry_a_1.csv', 'train_tax_registry_b_1.csv', 'train_tax_registry_c_1.csv', 'train_credit_bureau_b_1.csv', 'train_other_1.csv', 'train_person_1.csv', 'train_deposit_1.csv', 'train_debitcard_1.csv', 'train_credit_bureau_b_2.csv'] #[filename for filename in filename_list_with_regular_expressions if not filename in filename_star_list]\n",
    "# filename_list_with_regular_expressions = ['train_base.csv', 'train_static_cb_0.csv', 'train_static_0_*.csv', 'train_applprev_1_*.csv', 'train_tax_registry_a_1.csv', 'train_tax_registry_b_1.csv', 'train_tax_registry_c_1.csv', 'train_credit_bureau_a_1_*.csv', 'train_credit_bureau_b_1.csv', 'train_other_1.csv', 'train_person_1.csv', 'train_deposit_1.csv', 'train_debitcard_1.csv', 'train_credit_bureau_b_2.csv', 'train_credit_bureau_a_2_*.csv']\n",
    "preview_list(filename_star_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc724c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_base.csv',\n",
       " 'train_static_cb_0.csv',\n",
       " 'train_tax_registry_a_1.csv',\n",
       " 'train_tax_registry_b_1.csv',\n",
       " 'train_tax_registry_c_1.csv',\n",
       " 'train_credit_bureau_b_1.csv',\n",
       " 'train_other_1.csv',\n",
       " 'train_person_1.csv',\n",
       " 'train_deposit_1.csv',\n",
       " 'train_debitcard_1.csv',\n",
       " 'train_credit_bureau_b_2.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.59 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "preview_list(filename_single_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5fb41",
   "metadata": {},
   "source": [
    "### Create a Database Table for Each .CSV Filename List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b8dee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename_regular_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename_star \u001b[38;5;129;01min\u001b[39;00m filename_star_list:    \n\u001b[0;32m----> 2\u001b[0m     _ \u001b[38;5;241m=\u001b[39m create_database_table_and_return_dataframe_from_filename_regular_expression(\u001b[43mfilename_regular_expression\u001b[49m, return_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename_regular_expression' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 307 ms (started: 2024-04-11 13:01:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "for filename_regular_expression in filename_star_list:    \n",
    "    _ = create_database_table_and_return_dataframe_from_filename_regular_expression(filename_regular_expression, return_result=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Database Table Names\n",
    "query=\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\"\n",
    "result=execute_query(connection, query=query, table_name=None, column_name_list=None)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10463e",
   "metadata": {},
   "source": [
    "### Create a Database Table for Each Single .CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filename_single_list:\n",
    "    create_database_table_and_return_dataframe_from_single_filename(filename=filename, return_result=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Database Table Names\n",
    "query=\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\"\n",
    "result=execute_query(connection, query=query, table_name=None, column_name_list=None)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d83eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00cc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a7a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd75c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140032e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupy_the_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b91c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176781be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f595a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07577378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b99943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6f8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5d4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab1de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432c73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19673861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be45bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_result\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='train_credit_bureau_a_2_5.csv'\n",
    "\n",
    "# df_train_credit_bureau_a_2_5=pd.read_csv(configuration.train_data_directory_path+filename)\n",
    "# preview_df(df_train_credit_bureau_a_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b282df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_train_credit_bureau_a_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29495d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd50282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504f218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2c7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3a045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab21dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb402393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691aaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4def27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad5a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cc15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6129a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e66b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c57f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f97b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf9a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir()\n",
    "# %who_ls\n",
    "# %who_ls function\n",
    "# %who_ls str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c77f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3792595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locals()\n",
    "# globals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269060cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086762fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_collection={}\n",
    "\n",
    "key='feature_definitions'\n",
    "relative_filename_path=os.path.join(\"..\", \"data\", \"raw\", str(key)+\".csv\")\n",
    "df_collection[key]=pd.read_csv(relative_filename_path)\n",
    "\n",
    "print(df_collection[key].shape)\n",
    "df_collection[key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4e003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76046de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52039f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#in postgresql ordered table and replace the original table???\n",
    "\n",
    "# -- Step 1: Create a new table with the desired order\n",
    "# CREATE TABLE new_table_name (\n",
    "#     -- Define columns similar to the original table\n",
    "#     column1 datatype,\n",
    "#     column2 datatype,\n",
    "#     ...\n",
    "# );\n",
    "\n",
    "# -- Step 2: Copy data from the original table to the new table, ordering it as needed\n",
    "# INSERT INTO new_table_name\n",
    "# SELECT *\n",
    "# FROM original_table_name\n",
    "# ORDER BY column_to_order_by;\n",
    "\n",
    "# -- Step 3: Drop the original table\n",
    "# DROP TABLE original_table_name;\n",
    "\n",
    "# -- Step 4: Rename the new table to match the original table's name\n",
    "# ALTER TABLE new_table_name RENAME TO original_table_name;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52125b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7751f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database table schema includes the column names, data types, constraints, and relationships with other tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b4e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# variable_sizes = {name: sys.getsizeof(value) for name, value in locals().items()}\n",
    "# for name, size in variable_sizes.items():\n",
    "#     print(f\"{name}: {size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# def get_files_and_sizes(directory):\n",
    "#     files_and_sizes = {}\n",
    "#     for filename in os.listdir(directory):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "#         if os.path.isfile(filepath):\n",
    "#             file_size_bytes = os.path.getsize(filepath)\n",
    "#             file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "#             files_and_sizes[filename] = file_size_mb\n",
    "#     return files_and_sizes\n",
    "\n",
    "# files_and_sizes = get_files_and_sizes('/Users/pauljacob/MyDrive_pauljacob.datascience1@gmail.com/Projects/Home_Credit_Risk/data/raw/train/')\n",
    "# for filename, size_mb in files_and_sizes.items():\n",
    "#     print(f\"{filename}: {size_mb:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5564855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a02d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_the_files_into_a_dataframe(filename_path_regular_expression):\n",
    "\n",
    "    filename_path_list = glob(str(filename_path_regular_expression))\n",
    "    print(f'len(filename_path_list): {len(filename_path_list)}')\n",
    "    filename_path_list.sort()\n",
    "\n",
    "    df_list = [pd.read_csv(filename_path) for filename_path in filename_path_list]\n",
    "    \n",
    "    return pd.concat(df_list, axis=0).drop_duplicates()\n",
    "\n",
    "# filename_regular_expression = 'train_static_0_*.csv'\n",
    "# df_train_static_0_star = read_the_files_into_a_dataframe(configuration.train_data_directory_path+filename_regular_expression)\n",
    "# preview_df(df_train_static_0_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da95cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Create and Copy into the Table 'train_applprev' the Data of 'train_applprev_1_0.csv' and 'train_applprev_1_1.csv'\n",
    "\n",
    "\n",
    "# #Drop Tables\n",
    "# table_name='feature_definitions, train_applprev_1_0, train_applprev_1_1, train_applprev'\n",
    "# query = \"DROP TABLE IF EXISTS {};\".format(table_name)\n",
    "# execute_query(connection, query=query, table_name=table_name, column_name_list=None)\n",
    "\n",
    "\n",
    "# #Create Table 'train_applprev'\n",
    "# table_name='train_applprev'\n",
    "# column_name_list=['case_id', 'actualdpd_943P', 'annuity_853A', 'approvaldate_319D', 'byoccupationinc_3656910L', 'cancelreason_3545846M', 'childnum_21L', 'creationdate_885D', 'credacc_actualbalance_314A', 'credacc_credlmt_575A', 'credacc_maxhisbal_375A', 'credacc_minhisbal_90A', 'credacc_status_367L', 'credacc_transactions_402L', 'credamount_590A', 'credtype_587L', 'currdebt_94A', 'dateactivated_425D', 'district_544M', 'downpmt_134A', 'dtlastpmt_581D', 'dtlastpmtallstes_3545839D', 'education_1138M', 'employedfrom_700D', 'familystate_726L', 'firstnonzeroinstldate_307D', 'inittransactioncode_279L', 'isbidproduct_390L', 'isdebitcard_527L', 'mainoccupationinc_437A', 'maxdpdtolerance_577P', 'num_group1', 'outstandingdebt_522A', 'pmtnum_8L', 'postype_4733339M', 'profession_152M', 'rejectreason_755M', 'rejectreasonclient_4145042M', 'revolvingaccount_394A', 'status_219L', 'tenor_203L']\n",
    "# data_type_list=['INTEGER',   'NUMERIC',        'NUMERIC',      'DATE',              'NUMERIC',                  'VARCHAR',               'NUMERIC',      'DATE',              'NUMERIC',                    'NUMERIC',              'NUMERIC',                'NUMERIC',               'VARCHAR',             'NUMERIC',                   'NUMERIC',         'VARCHAR',       'NUMERIC',      'DATE',               'VARCHAR',       'NUMERIC',      'DATE',           'DATE',                      'VARCHAR',         'DATE',              'VARCHAR',          'DATE',                       'VARCHAR',                  'BOOLEAN',           'BOOLEAN',          'NUMERIC',                'NUMERIC',              'INTEGER',    'NUMERIC',              'NUMERIC',   'VARCHAR',          'VARCHAR',         'VARCHAR',           'VARCHAR',                     'NUMERIC',               'VARCHAR',     'NUMERIC' ]\n",
    "# #data_type_list=['VARCHAR(255)']+['NUMERIC']+  ['NUMERIC']+    ['DATE']+            ['NUMERIC']+                ['VARCHAR(255)']+        ['NUMERIC']+    ['DATE']+            ['NUMERIC']+                  ['NUMERIC']+            ['VARCHAR(255)']*(41-10)\n",
    "# #                               ['SMALLINT']                                                                                            ['INTEGER']\n",
    "# query = construct_query_from_table_name_column_name_list_and_data_type_list(table_name=table_name, column_name_list=column_name_list, data_type_list=data_type_list)\n",
    "# execute_query(connection, query=query, table_name=table_name)\n",
    "\n",
    "\n",
    "# #Copy in the Data 'train_applprev_1_0.csv'\n",
    "# # Enable Read and Execute Permissions to the File \"train_applprev_1_0.csv\"\n",
    "# filename_path = \"/Users/pauljacob/MyDrive_pauljacob.datascience1@gmail.com/Projects/Home_Credit_Risk/data/raw/train/train_applprev_1_0.csv\"\n",
    "# filename_parent_paths=generate_parent_paths_from(filename_path=filename_path)\n",
    "# command = \"chmod a+rX {}\".format(filename_parent_paths); subprocess.run(command, shell=True)\n",
    "\n",
    "# #Copy Data into Table 'train_applprev'\n",
    "# query = \"copy {} FROM '{}' DELIMITER ',' CSV HEADER;\".format(table_name, filename_path)\n",
    "# execute_query(connection, query=query, table_name=table_name)\n",
    "\n",
    "\n",
    "\n",
    "# #Copy in the Data 'train_applprev_1_1.csv'\n",
    "# # Enable Read and Execute Permissions to the File \"train_applprev_1_0.csv\"\n",
    "# filename_path = \"/Users/pauljacob/MyDrive_pauljacob.datascience1@gmail.com/Projects/Home_Credit_Risk/data/raw/train/train_applprev_1_1.csv\"\n",
    "# filename_parent_paths=generate_parent_paths_from(filename_path=filename_path)\n",
    "# command = \"chmod a+rX {}\".format(filename_parent_paths); subprocess.run(command, shell=True)\n",
    "\n",
    "# #Copy Data into Table 'train_applprev'\n",
    "# query = \"copy {} FROM '{}' DELIMITER ',' CSV HEADER;\".format(table_name, filename_path)\n",
    "# execute_query(connection, query=query, table_name=table_name) #Add efficiency? #Source: https://hakibenita.com/fast-load-data-python-postgresql#benchmark\n",
    "# #time: 32 s (started: 2024-04-09 19:00:31 -07:00)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ###  Alter Type to SMALLINT / INTEGER from NUMERIC\n",
    "\n",
    "\n",
    "# ###  Alter Type to SMALLINT from NUMERIC: Column Name 'actualdpd_943P', i.e. Days Past Due (DPD) of previous contract (actual).\n",
    "# table_name='train_applprev'\n",
    "# column_name='actualdpd_943P'\n",
    "# data_type='SMALLINT'\n",
    "# query=\"ALTER TABLE {} ALTER COLUMN {} TYPE {} USING {}::{};\".format(table_name, column_name, data_type, column_name, data_type)\n",
    "# execute_query(connection, query=query, table_name=table_name, column_name_list=[column_name])\n",
    "\n",
    "\n",
    "# ### Alter Type to INTEGER from NUMERIC: Column Name 'childnum_21L', i.e. Number of children in the previous application.\n",
    "# column_name='childnum_21L'\n",
    "# table_name='train_applprev'\n",
    "# data_type='INTEGER'\n",
    "# query=\"ALTER TABLE {} ALTER COLUMN {} TYPE {} USING ROUND({}::NUMERIC, 0);\".format(table_name, column_name, data_type, column_name)\n",
    "# execute_query(connection=connection, query=query, table_name=table_name, column_name_list=[column_name])\n",
    "\n",
    "# #time: 1min 1s (started: 2024-04-09 19:01:03 -07:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7408ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def csv_read(filename):\n",
    "#     '''Efficient .CSV File Read'''\n",
    "#     df_sample = pd.read_csv(filename, nrows=10000)\n",
    "#     column_data_type_dictionary = dict(zip(df_sample.columns, df_sample.dtypes))\n",
    "#     return pd.read_csv(filename, dtype=column_data_type_dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85f354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844088bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a83f4d01",
   "metadata": {},
   "source": [
    "### Alter Type to NUMERIC from VARCHAR(255): Column Name 'annuity_853A', i.e. Monthly annuity for previous applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41885f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39589e4c",
   "metadata": {},
   "source": [
    "### Alter Type to DATE from VARCHAR: Column Name 'approvaldate_319D', i.e. Approval Date of Previous Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a1e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29783cfe",
   "metadata": {},
   "source": [
    "### Alter Type to NUMERIC from VARCHAR: Column Name 'byoccupationinc_3656910L', i.e. Applicant's Income from Previous Applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1864f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b2b5bd",
   "metadata": {},
   "source": [
    "### Alter Type to VARCHAR from VARCHAR: Column Name 'cancelreason_3545846M', i.e. Application cancellation reason.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26058cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc266a65",
   "metadata": {},
   "source": [
    "### Alter Type to DATE from VARCHAR: Column Name 'creationdate_885D', i.e. Date when previous application was created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab015b7b",
   "metadata": {},
   "source": [
    "### Alter Type to NUMERIC from VARCHAR: Column Name 'credacc_actualbalance_314A', i.e. Actual balance on credit account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e281b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab14b8f8",
   "metadata": {},
   "source": [
    "### Alter Type to NUMERIC from VARCHAR: Column Name 'credacc_credlmt_575A', i.e. Credit card credit limit provided for previous applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d4032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1df7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a database and return it as a pandas dataframe for viewing\n",
    "\n",
    "# filename='train_base.csv'\n",
    "# df_result=create_database_table_and_return_dataframe_from_single_filename(filename=filename, return_result=True)\n",
    "# preview_df(df_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bbb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d823d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd871bff",
   "metadata": {},
   "source": [
    "### Create Database Table 'train_base' with Columns: 'case_id', 'date_decision', 'MONTH', 'WEEK_NUM', 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75396b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3329a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741701d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_static_0_1 = pd.read_csv(configuration.train_data_directory_path+'train_static_0_1.csv')\n",
    "# preview_df(df_train_static_0_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441aede8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85702564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04a9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778a1879",
   "metadata": {},
   "source": [
    "### Create Database Table 'train_static_0' from 'train_static_0_*.csv' with Columns: ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57aeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a database and return it as a pandas dataframe for viewing\n",
    "filename_regular_expression='train_static_0_*.csv'\n",
    "df_train_static_0 = create_database_table_and_return_dataframe_from_filename_regular_expression(filename_regular_expression, return_result=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
